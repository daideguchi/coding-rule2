#!/usr/bin/env python3
"""
AIåˆ¶å¾¡ãƒ«ãƒ¼ãƒ«ãƒ—ãƒ­ãƒ€ã‚¯ãƒˆæ§‹æˆã®å¾¹åº•çš„è©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ 
O3 + Gemini ã«ã‚ˆã‚‹åŒ…æ‹¬çš„åˆ†æã¨æ”¹å–„ææ¡ˆ
"""

import os
import json
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Tuple
import subprocess

class ComprehensiveStructureEvaluator:
    """æ§‹é€ è©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self, project_root: str = "."):
        self.project_root = Path(project_root)
        self.evaluation_result = {}
        
    def analyze_current_structure(self) -> Dict:
        """ç¾åœ¨ã®æ§‹é€ åˆ†æ"""
        structure = {
            "root_directories": [],
            "total_files": 0,
            "file_distribution": {},
            "key_components": [],
            "rule_files": [],
            "ai_specific_dirs": [],
            "complexity_metrics": {}
        }
        
        # ãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªåˆ†æ
        for item in self.project_root.iterdir():
            if item.is_dir() and not item.name.startswith('.'):
                structure["root_directories"].append({
                    "name": item.name,
                    "file_count": len(list(item.rglob("*"))),
                    "subdirs": len([d for d in item.iterdir() if d.is_dir()]),
                    "purpose": self._identify_directory_purpose(item.name)
                })
        
        # ãƒ•ã‚¡ã‚¤ãƒ«åˆ†å¸ƒåˆ†æ
        for ext in ['.py', '.sh', '.md', '.json', '.yml', '.yaml']:
            files = list(self.project_root.rglob(f"*{ext}"))
            structure["file_distribution"][ext] = len(files)
            structure["total_files"] += len(files)
        
        # é‡è¦ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆç¢ºèª
        key_files = [
            "STATUS.md", "0-ROOT.yml", "CLAUDE.md", "Makefile",
            "pyproject.toml", ".gitignore"
        ]
        for key_file in key_files:
            if (self.project_root / key_file).exists():
                structure["key_components"].append(key_file)
        
        # ãƒ«ãƒ¼ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª
        rule_patterns = ["*rules*", "*RULE*", "*.mdc", "*policy*"]
        for pattern in rule_patterns:
            structure["rule_files"].extend([
                str(f.relative_to(self.project_root)) 
                for f in self.project_root.rglob(pattern) 
                if f.is_file()
            ])
        
        # AIç‰¹åŒ–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªç¢ºèª
        ai_dirs = ["data", "models", "api", "compliance", "runtime", "ai-agents"]
        for ai_dir in ai_dirs:
            if (self.project_root / ai_dir).exists():
                structure["ai_specific_dirs"].append(ai_dir)
        
        # è¤‡é›‘ã•ãƒ¡ãƒˆãƒªã‚¯ã‚¹
        structure["complexity_metrics"] = {
            "directory_depth": self._calculate_max_depth(),
            "circular_references": self._check_circular_references(),
            "orphaned_files": self._find_orphaned_files(),
            "duplicate_patterns": self._analyze_duplicate_patterns()
        }
        
        return structure
    
    def _identify_directory_purpose(self, dir_name: str) -> str:
        """ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ç›®çš„è­˜åˆ¥"""
        purpose_map = {
            "src": "Source code",
            "docs": "Documentation", 
            "tests": "Test files",
            "scripts": "Utility scripts",
            "data": "AI/ML data assets",
            "models": "ML models",
            "api": "API definitions",
            "compliance": "Governance & ethics",
            "runtime": "Runtime data",
            "config": "Configuration",
            "ops": "Operations",
            "validation": "Validation"
        }
        return purpose_map.get(dir_name.lower(), "Unknown/Custom")
    
    def _calculate_max_depth(self) -> int:
        """æœ€å¤§ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ·±åº¦è¨ˆç®—"""
        max_depth = 0
        for path in self.project_root.rglob("*"):
            if path.is_dir():
                depth = len(path.relative_to(self.project_root).parts)
                max_depth = max(max_depth, depth)
        return max_depth
    
    def _check_circular_references(self) -> List[str]:
        """å¾ªç’°å‚ç…§ãƒã‚§ãƒƒã‚¯"""
        # ç°¡æ˜“å®Ÿè£…ï¼šã‚·ãƒ³ãƒœãƒªãƒƒã‚¯ãƒªãƒ³ã‚¯ã®å¾ªç’°ç¢ºèª
        circular_refs = []
        for path in self.project_root.rglob("*"):
            if path.is_symlink():
                try:
                    target = path.resolve()
                    if not target.exists():
                        circular_refs.append(str(path))
                except:
                    circular_refs.append(str(path))
        return circular_refs
    
    def _find_orphaned_files(self) -> List[str]:
        """å­¤ç«‹ãƒ•ã‚¡ã‚¤ãƒ«æ¤œå‡º"""
        orphaned = []
        for file_path in self.project_root.rglob("*"):
            if file_path.is_file():
                # è¦ªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«READMEãŒãªãã€ä¸€äººã¼ã£ã¡ã®ãƒ•ã‚¡ã‚¤ãƒ«
                parent = file_path.parent
                siblings = [f for f in parent.iterdir() if f.is_file()]
                if len(siblings) == 1 and not any(s.name.startswith('README') for s in parent.iterdir()):
                    orphaned.append(str(file_path.relative_to(self.project_root)))
        return orphaned[:10]  # æœ€å¤§10å€‹ã¾ã§
    
    def _analyze_duplicate_patterns(self) -> Dict:
        """é‡è¤‡ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ"""
        name_counts = {}
        for path in self.project_root.rglob("*"):
            if path.is_file():
                name = path.name
                if name not in name_counts:
                    name_counts[name] = 0
                name_counts[name] += 1
        
        duplicates = {name: count for name, count in name_counts.items() if count > 1}
        return dict(sorted(duplicates.items(), key=lambda x: x[1], reverse=True)[:10])
    
    def evaluate_ai_product_requirements(self, structure: Dict) -> Dict:
        """AIåˆ¶å¾¡ãƒ«ãƒ¼ãƒ«ãƒ—ãƒ­ãƒ€ã‚¯ãƒˆã¨ã—ã¦ã®è¦ä»¶è©•ä¾¡"""
        requirements = {
            "ai_governance": {
                "score": 0,
                "max_score": 100,
                "checks": []
            },
            "rule_management": {
                "score": 0, 
                "max_score": 100,
                "checks": []
            },
            "automation": {
                "score": 0,
                "max_score": 100,
                "checks": []
            },
            "scalability": {
                "score": 0,
                "max_score": 100,
                "checks": []
            }
        }
        
        # AI ã‚¬ãƒãƒŠãƒ³ã‚¹è©•ä¾¡
        ai_gov_checks = [
            ("compliance/ directory exists", "compliance" in structure["ai_specific_dirs"], 25),
            ("0-ROOT.yml constitutional rules", "0-ROOT.yml" in structure["key_components"], 25),
            ("AI ethics documentation", any("ethics" in rf.lower() for rf in structure["rule_files"]), 20),
            ("Model governance structure", "models" in structure["ai_specific_dirs"], 20),
            ("Data governance structure", "data" in structure["ai_specific_dirs"], 10)
        ]
        
        for check_name, passed, points in ai_gov_checks:
            requirements["ai_governance"]["checks"].append({
                "name": check_name,
                "passed": passed,
                "points": points if passed else 0
            })
            if passed:
                requirements["ai_governance"]["score"] += points
        
        # ãƒ«ãƒ¼ãƒ«ç®¡ç†è©•ä¾¡
        rule_mgmt_checks = [
            ("Hierarchical rule structure", len(structure["rule_files"]) >= 5, 30),
            ("Rule versioning system", any("version" in rf.lower() for rf in structure["rule_files"]), 20),
            ("Automated rule validation", any("validate" in rf.lower() for rf in structure["rule_files"]), 25),
            ("Rule documentation", len([rf for rf in structure["rule_files"] if rf.endswith('.md')]) >= 3, 25)
        ]
        
        for check_name, passed, points in rule_mgmt_checks:
            requirements["rule_management"]["checks"].append({
                "name": check_name,
                "passed": passed,
                "points": points if passed else 0
            })
            if passed:
                requirements["rule_management"]["score"] += points
        
        # è‡ªå‹•åŒ–è©•ä¾¡
        automation_checks = [
            ("Scripts directory", any(d["name"] == "scripts" for d in structure["root_directories"]), 25),
            ("Runtime monitoring", "runtime" in structure["ai_specific_dirs"], 25),
            ("Automated status system", "STATUS.md" in structure["key_components"], 25),
            ("CI/CD integration", any("github" in rf.lower() or "workflow" in rf.lower() for rf in structure["rule_files"]), 25)
        ]
        
        for check_name, passed, points in automation_checks:
            requirements["automation"]["checks"].append({
                "name": check_name,
                "passed": passed,
                "points": points if passed else 0
            })
            if passed:
                requirements["automation"]["score"] += points
        
        # ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£è©•ä¾¡
        scalability_checks = [
            ("Directory count optimization", len(structure["root_directories"]) <= 12, 25),
            ("Modular API structure", "api" in structure["ai_specific_dirs"], 25),
            ("Configuration management", any(d["name"] == "config" for d in structure["root_directories"]), 20),
            ("Low complexity", structure["complexity_metrics"]["directory_depth"] <= 6, 30)
        ]
        
        for check_name, passed, points in scalability_checks:
            requirements["scalability"]["checks"].append({
                "name": check_name,
                "passed": passed,
                "points": points if passed else 0
            })
            if passed:
                requirements["scalability"]["score"] += points
        
        return requirements
    
    def generate_o3_evaluation_prompt(self, structure: Dict, requirements: Dict) -> str:
        """O3è©•ä¾¡ç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ"""
        return f"""
COMPREHENSIVE PROJECT STRUCTURE EVALUATION REQUEST

## Project Overview
This is an AI control rule product with the following current structure:

### Root Directories ({len(structure['root_directories'])})
{chr(10).join([f"- {d['name']}: {d['file_count']} files, purpose: {d['purpose']}" for d in structure['root_directories']])}

### File Distribution
{chr(10).join([f"- {ext}: {count} files" for ext, count in structure['file_distribution'].items()])}

### AI-Specific Components
{chr(10).join([f"- {comp}" for comp in structure['ai_specific_dirs']])}

### Complexity Metrics
- Max directory depth: {structure['complexity_metrics']['directory_depth']}
- Duplicate file patterns: {len(structure['complexity_metrics']['duplicate_patterns'])}
- Orphaned files: {len(structure['complexity_metrics']['orphaned_files'])}

### Current AI Product Requirements Score
- AI Governance: {requirements['ai_governance']['score']}/100
- Rule Management: {requirements['rule_management']['score']}/100  
- Automation: {requirements['automation']['score']}/100
- Scalability: {requirements['scalability']['score']}/100

## Evaluation Questions

Please provide a comprehensive evaluation addressing:

1. **STRUCTURAL EXCELLENCE**: How does this structure compare to enterprise-grade AI governance products? Rate 1-10 and explain.

2. **AI CONTROL PRODUCT FITNESS**: Is this structure optimal for an AI rule control system? What are the critical gaps?

3. **SCALABILITY CONCERNS**: Can this structure handle 10x growth in rules, models, and data? What would break first?

4. **SECURITY & GOVERNANCE**: How well does this support AI ethics, compliance, and auditability requirements?

5. **DEVELOPER EXPERIENCE**: How intuitive is this structure for AI engineers, governance teams, and operators?

6. **IMMEDIATE IMPROVEMENTS**: What are the top 5 most critical structural changes needed?

7. **ANTI-PATTERNS**: What anti-patterns do you see that could cause problems?

8. **INDUSTRY STANDARDS**: How does this compare to industry standards for AI governance platforms?

Please be brutally honest and specific in your recommendations.
"""
    
    def generate_gemini_evaluation_prompt(self, structure: Dict, requirements: Dict) -> str:
        """Geminiè©•ä¾¡ç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ"""
        return f"""
AI/ML PRODUCT ARCHITECTURE EVALUATION

## Context
Evaluating a production AI control and governance system structure for enterprise deployment.

## Current Architecture Analysis

### Directory Structure
{json.dumps(structure['root_directories'], indent=2)}

### AI/ML Specific Assessment
- Data management: {'âœ…' if 'data' in structure['ai_specific_dirs'] else 'âŒ'}
- Model governance: {'âœ…' if 'models' in structure['ai_specific_dirs'] else 'âŒ'}
- API standardization: {'âœ…' if 'api' in structure['ai_specific_dirs'] else 'âŒ'}
- Compliance framework: {'âœ…' if 'compliance' in structure['ai_specific_dirs'] else 'âŒ'}

### Technical Metrics
- Codebase size: {structure['total_files']} files
- Max depth: {structure['complexity_metrics']['directory_depth']} levels
- Rule files: {len(structure['rule_files'])} files

## Gemini-Specific Evaluation Areas

1. **MLOps READINESS**: How well does this support ML model lifecycle management? Missing components?

2. **DATA GOVERNANCE**: Is the data/ structure sufficient for enterprise AI data management?

3. **MODEL VERSIONING**: How would you implement model versioning and experiment tracking in this structure?

4. **AI SAFETY**: Does this structure adequately support AI safety, testing, and validation workflows?

5. **MULTI-MODEL ORCHESTRATION**: Can this handle multiple AI models with different requirements?

6. **COMPLIANCE AUTOMATION**: How well does this support automated compliance checking and reporting?

7. **API GATEWAY PATTERNS**: Is the api/ structure suitable for microservices and API management?

8. **MONITORING & OBSERVABILITY**: What's missing for production AI system monitoring?

9. **DEPLOYMENT PATTERNS**: How would you structure this for container/K8s deployment?

10. **SECURITY ARCHITECTURE**: What security concerns do you see in this structure?

Please provide specific, actionable recommendations for each area.
"""
    
    def run_comprehensive_evaluation(self) -> Dict:
        """åŒ…æ‹¬çš„è©•ä¾¡å®Ÿè¡Œ"""
        print("ğŸ” åŒ…æ‹¬çš„æ§‹é€ è©•ä¾¡é–‹å§‹...")
        
        # 1. ç¾åœ¨æ§‹é€ åˆ†æ
        structure = self.analyze_current_structure()
        print(f"âœ… æ§‹é€ åˆ†æå®Œäº†: {len(structure['root_directories'])}ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª, {structure['total_files']}ãƒ•ã‚¡ã‚¤ãƒ«")
        
        # 2. AI ãƒ—ãƒ­ãƒ€ã‚¯ãƒˆè¦ä»¶è©•ä¾¡
        requirements = self.evaluate_ai_product_requirements(structure)
        print(f"âœ… è¦ä»¶è©•ä¾¡å®Œäº†: å¹³å‡ã‚¹ã‚³ã‚¢ {sum(req['score'] for req in requirements.values())/4:.1f}/100")
        
        # 3. O3 è©•ä¾¡
        print("ğŸ¤– O3ã«ã‚ˆã‚‹æ§‹é€ è©•ä¾¡å®Ÿè¡Œä¸­...")
        o3_prompt = self.generate_o3_evaluation_prompt(structure, requirements)
        
        # 4. Gemini è©•ä¾¡ 
        print("ğŸ¤– Geminiã«ã‚ˆã‚‹ AI/MLç‰¹åŒ–è©•ä¾¡å®Ÿè¡Œä¸­...")
        gemini_prompt = self.generate_gemini_evaluation_prompt(structure, requirements)
        
        evaluation_result = {
            "timestamp": datetime.now().isoformat(),
            "structure_analysis": structure,
            "requirements_assessment": requirements,
            "o3_evaluation_prompt": o3_prompt,
            "gemini_evaluation_prompt": gemini_prompt,
            "overall_health_score": sum(req['score'] for req in requirements.values()) / 4
        }
        
        return evaluation_result
    
    def save_evaluation_results(self, results: Dict):
        """è©•ä¾¡çµæœä¿å­˜"""
        output_file = self.project_root / "runtime" / f"structure-evaluation-{datetime.now().strftime('%Y%m%d-%H%M%S')}.json"
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False)
        
        print(f"ğŸ“Š è©•ä¾¡çµæœä¿å­˜: {output_file}")
        return output_file

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    evaluator = ComprehensiveStructureEvaluator()
    
    print("ğŸ¯ AIåˆ¶å¾¡ãƒ«ãƒ¼ãƒ«ãƒ—ãƒ­ãƒ€ã‚¯ãƒˆæ§‹é€ è©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ ")
    print("=" * 60)
    
    # åŒ…æ‹¬è©•ä¾¡å®Ÿè¡Œ
    results = evaluator.run_comprehensive_evaluation()
    
    # çµæœä¿å­˜
    output_file = evaluator.save_evaluation_results(results)
    
    # ã‚µãƒãƒªãƒ¼è¡¨ç¤º
    print(f"\nğŸ“‹ è©•ä¾¡ã‚µãƒãƒªãƒ¼:")
    print(f"  å…¨ä½“å¥å…¨æ€§ã‚¹ã‚³ã‚¢: {results['overall_health_score']:.1f}/100")
    print(f"  ãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ•°: {len(results['structure_analysis']['root_directories'])}")
    print(f"  AIç‰¹åŒ–ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ: {len(results['structure_analysis']['ai_specific_dirs'])}")
    print(f"  ãƒ«ãƒ¼ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(results['structure_analysis']['rule_files'])}")
    
    print(f"\nğŸ¤– AIè©•ä¾¡ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç¢ºèª:")
    print(f"  {output_file}")
    
    print(f"\nğŸ“‹ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
    print("  1. O3ã¨Geminiã«è©•ä¾¡ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’é€ä¿¡")
    print("  2. è©•ä¾¡çµæœã«åŸºã¥ãæ”¹å–„è¨ˆç”»ä½œæˆ")
    print("  3. æ§‹é€ æœ€é©åŒ–å®Ÿè¡Œ")
    
    return output_file

if __name__ == "__main__":
    main()