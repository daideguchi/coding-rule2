#!/bin/bash
# ğŸ§¹ AI-Agents Log Cleanup System
# å®‰å…¨ãªãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—â†’åˆ†é¡â†’çµ±åˆâ†’å‰Šé™¤ã®è‡ªå‹•åŒ–ã‚·ã‚¹ãƒ†ãƒ 

set -e

# è¨­å®š
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
LOGS_DIR="$SCRIPT_DIR/logs"
SESSIONS_DIR="$SCRIPT_DIR/sessions"
BACKUP_ROOT="$SCRIPT_DIR/backup-cleanup-$(date +%Y%m%d-%H%M%S)"
CLEANUP_LOG="$SCRIPT_DIR/cleanup-$(date +%Y%m%d-%H%M%S).log"

# ãƒ­ã‚°é–¢æ•°
log_info() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] INFO: $1" | tee -a "$CLEANUP_LOG"
}

log_success() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] SUCCESS: $1" | tee -a "$CLEANUP_LOG"
}

log_warn() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] WARN: $1" | tee -a "$CLEANUP_LOG"
}

log_error() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] ERROR: $1" | tee -a "$CLEANUP_LOG"
}

# Phase 1: è©³ç´°ãƒ•ã‚¡ã‚¤ãƒ«åˆ†æ
analyze_file_structure() {
    log_info "ğŸ” Phase 1: ãƒ•ã‚¡ã‚¤ãƒ«æ§‹é€ åˆ†æé–‹å§‹"
    
    echo "ğŸ“Š ãƒ•ã‚¡ã‚¤ãƒ«åˆ†æãƒ¬ãƒãƒ¼ãƒˆ" > "$BACKUP_ROOT/analysis-report.md"
    echo "========================" >> "$BACKUP_ROOT/analysis-report.md"
    echo "" >> "$BACKUP_ROOT/analysis-report.md"
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºåˆ†æ
    echo "## ğŸ“ˆ ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºåˆ†æ" >> "$BACKUP_ROOT/analysis-report.md"
    find "$LOGS_DIR" -type f -exec ls -lh {} \; | awk '{print $5, $9}' | sort -hr > "$BACKUP_ROOT/file-sizes.txt"
    
    # å¤§å®¹é‡ãƒ•ã‚¡ã‚¤ãƒ«ç‰¹å®š
    LARGE_FILES=$(find "$LOGS_DIR" -type f -size +1M)
    MEDIUM_FILES=$(find "$LOGS_DIR" -type f -size +100k -size -1M)
    SMALL_FILES=$(find "$LOGS_DIR" -type f -size -100k)
    
    echo "### ğŸ”´ å¤§å®¹é‡ãƒ•ã‚¡ã‚¤ãƒ« (>1MB): $(echo "$LARGE_FILES" | wc -l)å€‹" >> "$BACKUP_ROOT/analysis-report.md"
    echo "$LARGE_FILES" >> "$BACKUP_ROOT/analysis-report.md"
    echo "" >> "$BACKUP_ROOT/analysis-report.md"
    
    echo "### ğŸŸ¡ ä¸­å®¹é‡ãƒ•ã‚¡ã‚¤ãƒ« (100KB-1MB): $(echo "$MEDIUM_FILES" | wc -l)å€‹" >> "$BACKUP_ROOT/analysis-report.md"
    echo "$MEDIUM_FILES" >> "$BACKUP_ROOT/analysis-report.md"
    echo "" >> "$BACKUP_ROOT/analysis-report.md"
    
    echo "### ğŸŸ¢ å°å®¹é‡ãƒ•ã‚¡ã‚¤ãƒ« (<100KB): $(echo "$SMALL_FILES" | wc -l)å€‹" >> "$BACKUP_ROOT/analysis-report.md"
    echo "$SMALL_FILES" >> "$BACKUP_ROOT/analysis-report.md"
    echo "" >> "$BACKUP_ROOT/analysis-report.md"
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ç¨®åˆ¥åˆ†æ
    echo "## ğŸ“‚ ãƒ•ã‚¡ã‚¤ãƒ«ç¨®åˆ¥åˆ†æ" >> "$BACKUP_ROOT/analysis-report.md"
    STATUS_FILES=$(find "$LOGS_DIR" -name "*status*" -type f)
    ERROR_FILES=$(find "$LOGS_DIR" -name "*error*" -o -name "*ERROR*" -o -name "*FAIL*" -type f)
    MD_FILES=$(find "$LOGS_DIR" -name "*.md" -type f)
    LOG_FILES=$(find "$LOGS_DIR" -name "*.log" -type f)
    
    echo "- ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹é–¢é€£: $(echo "$STATUS_FILES" | wc -l)å€‹" >> "$BACKUP_ROOT/analysis-report.md"
    echo "- ã‚¨ãƒ©ãƒ¼é–¢é€£: $(echo "$ERROR_FILES" | wc -l)å€‹" >> "$BACKUP_ROOT/analysis-report.md"
    echo "- ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³: $(echo "$MD_FILES" | wc -l)å€‹" >> "$BACKUP_ROOT/analysis-report.md"
    echo "- ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«: $(echo "$LOG_FILES" | wc -l)å€‹" >> "$BACKUP_ROOT/analysis-report.md"
    
    # ç·ä½¿ç”¨å®¹é‡
    TOTAL_SIZE=$(du -sh "$LOGS_DIR" | cut -f1)
    echo "- ç·ä½¿ç”¨å®¹é‡: $TOTAL_SIZE" >> "$BACKUP_ROOT/analysis-report.md"
    
    log_success "ğŸ“Š ãƒ•ã‚¡ã‚¤ãƒ«æ§‹é€ åˆ†æå®Œäº† - ãƒ¬ãƒãƒ¼ãƒˆ: $BACKUP_ROOT/analysis-report.md"
}

# Phase 2: å®‰å…¨ãªãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ
create_safe_backup() {
    log_info "ğŸ’¾ Phase 2: å®‰å…¨ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆé–‹å§‹"
    
    # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ä½œæˆ
    mkdir -p "$BACKUP_ROOT"/{original,classified,consolidated}
    mkdir -p "$BACKUP_ROOT/original"/{logs,sessions}
    mkdir -p "$BACKUP_ROOT/classified"/{status,errors,system,misc}
    
    # å®Œå…¨ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ
    log_info "ğŸ“‹ å®Œå…¨ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆä¸­..."
    cp -r "$LOGS_DIR"/* "$BACKUP_ROOT/original/logs/" 2>/dev/null || true
    cp -r "$SESSIONS_DIR"/* "$BACKUP_ROOT/original/sessions/" 2>/dev/null || true
    
    # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æ¤œè¨¼
    ORIGINAL_COUNT=$(find "$LOGS_DIR" "$SESSIONS_DIR" -type f | wc -l)
    BACKUP_COUNT=$(find "$BACKUP_ROOT/original" -type f | wc -l)
    
    if [ "$ORIGINAL_COUNT" -eq "$BACKUP_COUNT" ]; then
        log_success "âœ… ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æ¤œè¨¼æˆåŠŸ: $ORIGINAL_COUNTå€‹ã®ãƒ•ã‚¡ã‚¤ãƒ«"
    else
        log_error "âŒ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æ¤œè¨¼å¤±æ•—: Original=$ORIGINAL_COUNT, Backup=$BACKUP_COUNT"
        exit 1
    fi
    
    # ãƒã‚§ãƒƒã‚¯ã‚µãƒ ä½œæˆ
    log_info "ğŸ”’ ãƒã‚§ãƒƒã‚¯ã‚µãƒ ç”Ÿæˆä¸­..."
    find "$BACKUP_ROOT/original" -type f -exec md5sum {} \; > "$BACKUP_ROOT/checksums.md5"
    
    # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
    cat > "$BACKUP_ROOT/backup-info.json" << EOF
{
  "timestamp": "$(date -Iseconds)",
  "original_location": "$LOGS_DIR",
  "file_count": $ORIGINAL_COUNT,
  "total_size": "$(du -sh "$LOGS_DIR" | cut -f1)",
  "backup_method": "complete_copy",
  "verification": "checksum_verified"
}
EOF
    
    log_success "ğŸ’¾ å®‰å…¨ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆå®Œäº†: $BACKUP_ROOT"
}

# Phase 3: ã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ãƒˆåˆ†é¡ã‚·ã‚¹ãƒ†ãƒ 
classify_files_intelligently() {
    log_info "ğŸ§  Phase 3: ã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ãƒˆåˆ†é¡é–‹å§‹"
    
    local classification_report="$BACKUP_ROOT/classification-report.md"
    echo "# ğŸ“‚ ãƒ•ã‚¡ã‚¤ãƒ«åˆ†é¡ãƒ¬ãƒãƒ¼ãƒˆ" > "$classification_report"
    echo "åˆ†é¡æ—¥æ™‚: $(date)" >> "$classification_report"
    echo "" >> "$classification_report"
    
    # åˆ†é¡ãƒ«ãƒ¼ãƒ«å®šç¾©
    classify_file() {
        local file="$1"
        local filename=$(basename "$file")
        local content_sample=$(head -10 "$file" 2>/dev/null || echo "")
        
        # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹é–¢é€£ãƒ•ã‚¡ã‚¤ãƒ«
        if [[ "$filename" =~ status|Status|STATUS ]] || [[ "$content_sample" =~ WORKER|ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹|ãƒãƒ¼ãƒ ãƒªãƒ¼ãƒ€ãƒ¼ ]]; then
            echo "status"
        # ã‚¨ãƒ©ãƒ¼ãƒ»éšœå®³é–¢é€£
        elif [[ "$filename" =~ error|Error|ERROR|FAIL|CRITICAL|FRUSTRATION ]] || [[ "$content_sample" =~ ERROR|CRITICAL|Failed ]]; then
            echo "errors"
        # ã‚·ã‚¹ãƒ†ãƒ ãƒ»è¨­å®šé–¢é€£
        elif [[ "$filename" =~ master|compliance|emergency|resource|timer|auto ]] || [[ "$content_sample" =~ MASTER|COMPLIANCE ]]; then
            echo "system"
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³é–¢é€£
        elif [[ "$filename" =~ session ]] || [[ "$content_sample" =~ session_id|role.*president|role.*boss ]]; then
            echo "sessions"
        # ãã®ä»–
        else
            echo "misc"
        fi
    }
    
    # ãƒ•ã‚¡ã‚¤ãƒ«åˆ†é¡å®Ÿè¡Œ
    declare -A category_counts
    category_counts[status]=0
    category_counts[errors]=0
    category_counts[system]=0
    category_counts[sessions]=0
    category_counts[misc]=0
    
    while IFS= read -r -d '' file; do
        if [ -f "$file" ]; then
            category=$(classify_file "$file")
            filename=$(basename "$file")
            
            # åˆ†é¡å…ˆã«ã‚³ãƒ”ãƒ¼
            cp "$file" "$BACKUP_ROOT/classified/$category/"
            category_counts[$category]=$((category_counts[$category] + 1))
            
            # åˆ†é¡ãƒ­ã‚°
            echo "[$category] $filename" >> "$classification_report"
            
            log_info "ğŸ“ åˆ†é¡: $filename â†’ $category"
        fi
    done < <(find "$BACKUP_ROOT/original" -type f -print0)
    
    # åˆ†é¡çµ±è¨ˆ
    echo "" >> "$classification_report"
    echo "## ğŸ“Š åˆ†é¡çµ±è¨ˆ" >> "$classification_report"
    for category in status errors system sessions misc; do
        echo "- $category: ${category_counts[$category]}å€‹" >> "$classification_report"
    done
    
    log_success "ğŸ§  ã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ãƒˆåˆ†é¡å®Œäº†: $classification_report"
}

# Phase 4: çµ±åˆã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ 
consolidate_logs() {
    log_info "ğŸ”— Phase 4: ãƒ­ã‚°çµ±åˆé–‹å§‹"
    
    local consolidated_dir="$BACKUP_ROOT/consolidated"
    mkdir -p "$consolidated_dir"/{unified,archive}
    
    # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãƒ­ã‚°çµ±åˆ
    log_info "ğŸ“Š ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãƒ­ã‚°çµ±åˆä¸­..."
    local unified_status="$consolidated_dir/unified/unified-status-$(date +%Y%m%d).log"
    echo "# ğŸ”„ çµ±åˆã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãƒ­ã‚°" > "$unified_status"
    echo "# çµ±åˆæ—¥æ™‚: $(date)" >> "$unified_status"
    echo "# çµ±åˆå…ƒãƒ•ã‚¡ã‚¤ãƒ«æ•°: $(find "$BACKUP_ROOT/classified/status" -type f | wc -l)" >> "$unified_status"
    echo "" >> "$unified_status"
    
    # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ™‚ç³»åˆ—ã§ãƒãƒ¼ã‚¸
    find "$BACKUP_ROOT/classified/status" -type f -name "*.log" | while read -r file; do
        echo "## === $(basename "$file") ===" >> "$unified_status"
        echo "ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: $(du -h "$file" | cut -f1)" >> "$unified_status"
        echo "æœ€çµ‚æ›´æ–°: $(stat -f "%Sm" -t "%Y-%m-%d %H:%M:%S" "$file" 2>/dev/null || date)" >> "$unified_status"
        echo "" >> "$unified_status"
        
        # å¤§å®¹é‡ãƒ•ã‚¡ã‚¤ãƒ«ã¯æœ€åˆã¨æœ€å¾Œã®100è¡Œã®ã¿
        if [ "$(wc -l < "$file")" -gt 1000 ]; then
            echo "[ãƒ•ã‚¡ã‚¤ãƒ«å…ˆé ­100è¡Œ]" >> "$unified_status"
            head -100 "$file" >> "$unified_status"
            echo "" >> "$unified_status"
            echo "[...ä¸­é–“éƒ¨åˆ†çœç•¥...]" >> "$unified_status"
            echo "" >> "$unified_status"
            echo "[ãƒ•ã‚¡ã‚¤ãƒ«æœ«å°¾100è¡Œ]" >> "$unified_status"
            tail -100 "$file" >> "$unified_status"
        else
            cat "$file" >> "$unified_status"
        fi
        echo "" >> "$unified_status"
        echo "=====================================%" >> "$unified_status"
        echo "" >> "$unified_status"
    done
    
    # ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°çµ±åˆ
    log_info "ğŸš¨ ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°çµ±åˆä¸­..."
    local unified_errors="$consolidated_dir/unified/unified-errors-$(date +%Y%m%d).log"
    echo "# ğŸš¨ çµ±åˆã‚¨ãƒ©ãƒ¼ãƒ­ã‚°" > "$unified_errors"
    echo "# çµ±åˆæ—¥æ™‚: $(date)" >> "$unified_errors"
    echo "" >> "$unified_errors"
    
    find "$BACKUP_ROOT/classified/errors" -type f | while read -r file; do
        echo "## === $(basename "$file") ===" >> "$unified_errors"
        cat "$file" >> "$unified_errors"
        echo "" >> "$unified_errors"
    done
    
    # ã‚·ã‚¹ãƒ†ãƒ ãƒ­ã‚°çµ±åˆ
    log_info "âš™ï¸ ã‚·ã‚¹ãƒ†ãƒ ãƒ­ã‚°çµ±åˆä¸­..."
    local unified_system="$consolidated_dir/unified/unified-system-$(date +%Y%m%d).log"
    echo "# âš™ï¸ çµ±åˆã‚·ã‚¹ãƒ†ãƒ ãƒ­ã‚°" > "$unified_system"
    echo "# çµ±åˆæ—¥æ™‚: $(date)" >> "$unified_system"
    echo "" >> "$unified_system"
    
    find "$BACKUP_ROOT/classified/system" -type f | while read -r file; do
        echo "## === $(basename "$file") ===" >> "$unified_system"
        cat "$file" >> "$unified_system"
        echo "" >> "$unified_system"
    done
    
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³æƒ…å ±çµ±åˆ
    log_info "ğŸ‘¥ ã‚»ãƒƒã‚·ãƒ§ãƒ³æƒ…å ±çµ±åˆä¸­..."
    local unified_sessions="$consolidated_dir/unified/unified-sessions-$(date +%Y%m%d).json"
    echo "{" > "$unified_sessions"
    echo "  \"consolidation_timestamp\": \"$(date -Iseconds)\"," >> "$unified_sessions"
    echo "  \"sessions\": [" >> "$unified_sessions"
    
    local first=true
    find "$BACKUP_ROOT/classified/sessions" -name "*.json" -type f | while read -r file; do
        if [ "$first" = true ]; then
            first=false
        else
            echo "," >> "$unified_sessions"
        fi
        cat "$file" >> "$unified_sessions"
    done
    
    echo "" >> "$unified_sessions"
    echo "  ]" >> "$unified_sessions"
    echo "}" >> "$unified_sessions"
    
    # çµ±åˆçµ±è¨ˆ
    local consolidation_stats="$consolidated_dir/consolidation-stats.json"
    cat > "$consolidation_stats" << EOF
{
  "consolidation_timestamp": "$(date -Iseconds)",
  "original_files": $(find "$BACKUP_ROOT/original" -type f | wc -l),
  "consolidated_files": $(find "$consolidated_dir/unified" -type f | wc -l),
  "space_savings": {
    "original_size": "$(du -sh "$BACKUP_ROOT/original" | cut -f1)",
    "consolidated_size": "$(du -sh "$consolidated_dir/unified" | cut -f1)"
  },
  "files_created": [
    "$(basename "$unified_status")",
    "$(basename "$unified_errors")",
    "$(basename "$unified_system")",
    "$(basename "$unified_sessions")"
  ]
}
EOF
    
    log_success "ğŸ”— ãƒ­ã‚°çµ±åˆå®Œäº†: $consolidated_dir"
}

# Phase 5: å®‰å…¨å‰Šé™¤ã‚·ã‚¹ãƒ†ãƒ 
safe_deletion_system() {
    log_info "ğŸ—‘ï¸ Phase 5: å®‰å…¨å‰Šé™¤ã‚·ã‚¹ãƒ†ãƒ é–‹å§‹"
    
    # å‰Šé™¤å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«ç‰¹å®š
    local deletion_plan="$BACKUP_ROOT/deletion-plan.md"
    echo "# ğŸ—‘ï¸ å‰Šé™¤è¨ˆç”»" > "$deletion_plan"
    echo "ä½œæˆæ—¥æ™‚: $(date)" >> "$deletion_plan"
    echo "" >> "$deletion_plan"
    
    # é‡è¤‡ãƒ•ã‚¡ã‚¤ãƒ«ç‰¹å®š
    echo "## ğŸ” å‰Šé™¤å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«" >> "$deletion_plan"
    echo "" >> "$deletion_plan"
    
    # å¤§å®¹é‡é‡è¤‡ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆçµ±åˆæ¸ˆã¿ï¼‰
    LARGE_REDUNDANT=(
        "persistent-status.log"
        "startup-status.log"
        "requirements-check.log"
    )
    
    # å°å®¹é‡é‡è¤‡ãƒ•ã‚¡ã‚¤ãƒ«
    SMALL_REDUNDANT=(
        "current-status-103231.log"
        "simple-status.log"
        "status-fix.log"
        "ultimate-status.log"
        "status-final.log"
    )
    
    # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«
    TEMPLATE_FILES=(
        "CRITICAL_ERROR_\$(date*"
        "current-analysis-\$(date*"
    )
    
    echo "### ğŸ”´ å¤§å®¹é‡é‡è¤‡ãƒ•ã‚¡ã‚¤ãƒ« (çµ±åˆæ¸ˆã¿)" >> "$deletion_plan"
    for file in "${LARGE_REDUNDANT[@]}"; do
        if [ -f "$LOGS_DIR/$file" ]; then
            local size=$(du -h "$LOGS_DIR/$file" | cut -f1)
            echo "- $file ($size)" >> "$deletion_plan"
        fi
    done
    echo "" >> "$deletion_plan"
    
    echo "### ğŸŸ¡ å°å®¹é‡é‡è¤‡ãƒ•ã‚¡ã‚¤ãƒ«" >> "$deletion_plan"
    for file in "${SMALL_REDUNDANT[@]}"; do
        if [ -f "$LOGS_DIR/$file" ]; then
            local size=$(du -h "$LOGS_DIR/$file" | cut -f1)
            echo "- $file ($size)" >> "$deletion_plan"
        fi
    done
    echo "" >> "$deletion_plan"
    
    echo "### ğŸŸ  ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«" >> "$deletion_plan"
    for pattern in "${TEMPLATE_FILES[@]}"; do
        find "$LOGS_DIR" -name "$pattern" -type f | while read -r file; do
            local size=$(du -h "$file" | cut -f1)
            echo "- $(basename "$file") ($size)" >> "$deletion_plan"
        done
    done
    echo "" >> "$deletion_plan"
    
    # å®‰å…¨æ€§ãƒã‚§ãƒƒã‚¯
    echo "## ğŸ›¡ï¸ å®‰å…¨æ€§ãƒã‚§ãƒƒã‚¯" >> "$deletion_plan"
    echo "- âœ… å®Œå…¨ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆæ¸ˆã¿" >> "$deletion_plan"
    echo "- âœ… ãƒã‚§ãƒƒã‚¯ã‚µãƒ æ¤œè¨¼æ¸ˆã¿" >> "$deletion_plan"
    echo "- âœ… ãƒ•ã‚¡ã‚¤ãƒ«åˆ†é¡æ¸ˆã¿" >> "$deletion_plan"
    echo "- âœ… ãƒ­ã‚°çµ±åˆæ¸ˆã¿" >> "$deletion_plan"
    echo "" >> "$deletion_plan"
    
    # å‰Šé™¤å®Ÿè¡Œ (ãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³)
    echo "## ğŸ”„ å‰Šé™¤ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³" >> "$deletion_plan"
    local total_savings=0
    
    # å®Ÿéš›ã®å‰Šé™¤ã¯ä¿ç•™ï¼ˆå®‰å…¨ã®ãŸã‚ï¼‰
    echo "âš ï¸ å®Ÿéš›ã®å‰Šé™¤ã¯æ‰‹å‹•ç¢ºèªå¾Œã«å®Ÿè¡Œã—ã¦ãã ã•ã„" >> "$deletion_plan"
    echo "" >> "$deletion_plan"
    echo "å‰Šé™¤ã‚³ãƒãƒ³ãƒ‰ä¾‹:" >> "$deletion_plan"
    
    for file in "${LARGE_REDUNDANT[@]}" "${SMALL_REDUNDANT[@]}"; do
        if [ -f "$LOGS_DIR/$file" ]; then
            echo "rm \"$LOGS_DIR/$file\"" >> "$deletion_plan"
        fi
    done
    
    for pattern in "${TEMPLATE_FILES[@]}"; do
        find "$LOGS_DIR" -name "$pattern" -type f | while read -r file; do
            echo "rm \"$file\"" >> "$deletion_plan"
        done
    done
    
    log_success "ğŸ—‘ï¸ å‰Šé™¤è¨ˆç”»ä½œæˆå®Œäº†: $deletion_plan"
}

# Phase 6: æ–°ã—ã„ãƒ­ã‚°ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ä½œæˆ
create_new_log_system() {
    log_info "ğŸ—ï¸ Phase 6: æ–°ãƒ­ã‚°ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ä½œæˆ"
    
    # æ–°ã—ã„ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ 
    mkdir -p "$LOGS_DIR"/{system,monitoring,archive}
    mkdir -p "$SESSIONS_DIR"/active
    
    # çµ±åˆãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
    local unified_status_new="$LOGS_DIR/monitoring/status-$(date +%Y%m%d).log"
    local unified_system_new="$LOGS_DIR/system/master-$(date +%Y%m%d).log"
    local unified_sessions_new="$SESSIONS_DIR/active/sessions-$(date +%Y%m%d).json"
    
    # çµ±åˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚³ãƒ”ãƒ¼
    cp "$BACKUP_ROOT/consolidated/unified/unified-status-$(date +%Y%m%d).log" "$unified_status_new"
    cp "$BACKUP_ROOT/consolidated/unified/unified-system-$(date +%Y%m%d).log" "$unified_system_new"
    cp "$BACKUP_ROOT/consolidated/unified/unified-sessions-$(date +%Y%m%d).json" "$unified_sessions_new"
    
    # ãƒ­ã‚°è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
    cat > "$LOGS_DIR/logging.conf" << EOF
# AI-Agents ãƒ­ã‚°è¨­å®š
# ä½œæˆæ—¥: $(date)

[logging]
enabled=true
level=INFO
rotation=daily
max_size=10MB
retention_days=30

[categories]
status="$LOGS_DIR/monitoring/"
system="$LOGS_DIR/system/"
errors="$LOGS_DIR/system/"
archive="$LOGS_DIR/archive/"

[sessions]
active_dir="$SESSIONS_DIR/active/"
archive_dir="$SESSIONS_DIR/archive/"
EOF
    
    # READMEä½œæˆ
    cat > "$LOGS_DIR/README.md" << EOF
# ğŸ§¹ AI-Agents ãƒ­ã‚°ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ 

## ğŸ“ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ 
- \`system/\`: ã‚·ã‚¹ãƒ†ãƒ ãƒ»ãƒã‚¹ã‚¿ãƒ¼ãƒ­ã‚°
- \`monitoring/\`: ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãƒ»ç›£è¦–ãƒ­ã‚°  
- \`archive/\`: ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã•ã‚ŒãŸå¤ã„ãƒ­ã‚°

## ğŸ”„ ãƒ­ã‚°ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³
- æ—¥æ¬¡ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³
- æœ€å¤§ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: 10MB
- ä¿æŒæœŸé–“: 30æ—¥

## ğŸ“Š çµ±åˆãƒ­ã‚°æƒ…å ±
- çµ±åˆå®Ÿè¡Œæ—¥: $(date)
- çµ±åˆå‰ãƒ•ã‚¡ã‚¤ãƒ«æ•°: $(find "$BACKUP_ROOT/original" -type f | wc -l)
- çµ±åˆå¾Œãƒ•ã‚¡ã‚¤ãƒ«æ•°: $(find "$LOGS_DIR" -type f | wc -l)
- ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å ´æ‰€: $BACKUP_ROOT

## ğŸ”„ å¾©å…ƒæ–¹æ³•
ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‹ã‚‰å¾©å…ƒã™ã‚‹å ´åˆ:
\`\`\`bash
cp -r $BACKUP_ROOT/original/logs/* $LOGS_DIR/
cp -r $BACKUP_ROOT/original/sessions/* $SESSIONS_DIR/
\`\`\`
EOF
    
    log_success "ğŸ—ï¸ æ–°ãƒ­ã‚°ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ä½œæˆå®Œäº†"
}

# ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°
main() {
    log_info "ğŸš€ AI-Agents ãƒ­ã‚°ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚·ã‚¹ãƒ†ãƒ é–‹å§‹"
    log_info "ğŸ“ ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: $SCRIPT_DIR"
    log_info "ğŸ’¾ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å…ˆ: $BACKUP_ROOT"
    
    # äº‹å‰ãƒã‚§ãƒƒã‚¯
    if [ ! -d "$LOGS_DIR" ]; then
        log_error "âŒ ãƒ­ã‚°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: $LOGS_DIR"
        exit 1
    fi
    
    # ãƒ•ã‚§ãƒ¼ã‚ºå®Ÿè¡Œ
    analyze_file_structure
    create_safe_backup  
    classify_files_intelligently
    consolidate_logs
    safe_deletion_system
    create_new_log_system
    
    # å®Œäº†ãƒ¬ãƒãƒ¼ãƒˆ
    local cleanup_report="$BACKUP_ROOT/cleanup-summary.md"
    cat > "$cleanup_report" << EOF
# ğŸ‰ AI-Agents ãƒ­ã‚°ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Œäº†ãƒ¬ãƒãƒ¼ãƒˆ

## ğŸ“Š å®Ÿè¡Œçµ±è¨ˆ
- å®Ÿè¡Œæ—¥æ™‚: $(date)
- å‡¦ç†ãƒ•ã‚¡ã‚¤ãƒ«æ•°: $(find "$BACKUP_ROOT/original" -type f | wc -l)
- ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚µã‚¤ã‚º: $(du -sh "$BACKUP_ROOT" | cut -f1)
- å®Ÿè¡Œæ™‚é–“: $SECONDS ç§’

## ğŸ“ ä½œæˆã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«
1. **ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—**: $BACKUP_ROOT/original/
2. **åˆ†é¡çµæœ**: $BACKUP_ROOT/classified/
3. **çµ±åˆãƒ­ã‚°**: $BACKUP_ROOT/consolidated/
4. **æ–°ã‚·ã‚¹ãƒ†ãƒ **: $LOGS_DIR/

## ğŸ›¡ï¸ å®‰å…¨æ©Ÿèƒ½
- âœ… å®Œå…¨ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ
- âœ… ãƒã‚§ãƒƒã‚¯ã‚µãƒ æ¤œè¨¼
- âœ… ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯å¯èƒ½
- âœ… æ®µéšçš„å®Ÿè¡Œ

## ğŸ“‹ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—
1. $cleanup_report ã‚’ç¢ºèª
2. $BACKUP_ROOT/deletion-plan.md ã§å‰Šé™¤è¨ˆç”»ç¢ºèª
3. å¿…è¦ã«å¿œã˜ã¦æ‰‹å‹•å‰Šé™¤å®Ÿè¡Œ
4. æ–°ãƒ­ã‚°ã‚·ã‚¹ãƒ†ãƒ ã®å‹•ä½œç¢ºèª

## ğŸ”„ ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯æ–¹æ³•
\`\`\`bash
# å®Œå…¨å¾©å…ƒ
rm -rf $LOGS_DIR/* $SESSIONS_DIR/*
cp -r $BACKUP_ROOT/original/logs/* $LOGS_DIR/
cp -r $BACKUP_ROOT/original/sessions/* $SESSIONS_DIR/
\`\`\`
EOF
    
    log_success "ğŸ‰ ãƒ­ã‚°ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚·ã‚¹ãƒ†ãƒ å®Œäº†"
    log_success "ğŸ“‹ å®Œäº†ãƒ¬ãƒãƒ¼ãƒˆ: $cleanup_report"
    log_success "ğŸ’¾ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—: $BACKUP_ROOT"
    
    echo ""
    echo "ğŸ” æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:"
    echo "1. ãƒ¬ãƒãƒ¼ãƒˆç¢ºèª: cat $cleanup_report"
    echo "2. å‰Šé™¤è¨ˆç”»ç¢ºèª: cat $BACKUP_ROOT/deletion-plan.md"
    echo "3. æ–°ã‚·ã‚¹ãƒ†ãƒ ç¢ºèª: ls -la $LOGS_DIR/"
}

# ã‚¹ã‚¯ãƒªãƒ—ãƒˆå®Ÿè¡Œ
case "${1:-main}" in
    "analyze")
        analyze_file_structure
        ;;
    "backup")
        create_safe_backup
        ;;
    "classify")
        classify_files_intelligently
        ;;
    "consolidate")
        consolidate_logs
        ;;
    "delete-plan")
        safe_deletion_system
        ;;
    "new-system")
        create_new_log_system
        ;;
    "main")
        main
        ;;
    *)
        echo "ä½¿ç”¨æ–¹æ³•:"
        echo "  $0 main          # å®Œå…¨å®Ÿè¡Œ"
        echo "  $0 analyze       # åˆ†æã®ã¿"
        echo "  $0 backup        # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã®ã¿"
        echo "  $0 classify      # åˆ†é¡ã®ã¿"
        echo "  $0 consolidate   # çµ±åˆã®ã¿"
        echo "  $0 delete-plan   # å‰Šé™¤è¨ˆç”»ã®ã¿"
        echo "  $0 new-system    # æ–°ã‚·ã‚¹ãƒ†ãƒ ã®ã¿"
        ;;
esac